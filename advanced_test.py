#!/usr/bin/env python3
"""
Crawl4AI é€²éšåŠŸèƒ½æ¸¬è©¦ç¯„ä¾‹
"""

import asyncio
import json
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig
from crawl4ai.extraction_strategy import CosineStrategy, LLMExtractionStrategy

async def structured_extraction_test():
    """çµæ§‹åŒ–è³‡æ–™æ“·å–æ¸¬è©¦"""
    print("ğŸ§  é–‹å§‹çµæ§‹åŒ–è³‡æ–™æ“·å–æ¸¬è©¦...")
    
    async with AsyncWebCrawler() as crawler:
        # ä½¿ç”¨ Cosine ç­–ç•¥æ“·å–ç›¸ä¼¼å…§å®¹
        cosine_strategy = CosineStrategy(
            semantic_filter="technology news",
            word_count_threshold=10,
            max_dist=0.2,
            linkage_method='ward',
            top_k=3
        )
        
        result = await crawler.arun(
            url="https://news.ycombinator.com",
            extraction_strategy=cosine_strategy
        )
        
        print(f"âœ… Cosine ç­–ç•¥æ“·å–å®Œæˆ")
        print(f"ğŸ“„ æ“·å–åˆ°çš„å…§å®¹å¡Šæ•¸: {len(result.extracted_content) if result.extracted_content else 0}")
        
        if result.extracted_content:
            for i, content in enumerate(result.extracted_content[:3], 1):
                print(f"   ğŸ“ å…§å®¹å¡Š {i}: {content[:100]}...")

async def javascript_execution_test():
    """JavaScript åŸ·è¡Œæ¸¬è©¦"""
    print("\nâš¡ é–‹å§‹ JavaScript åŸ·è¡Œæ¸¬è©¦...")
    
    js_code = """
    // ç²å–é é¢åŸºæœ¬è³‡è¨Š
    const info = {
        title: document.title,
        url: window.location.href,
        userAgent: navigator.userAgent,
        timestamp: new Date().toISOString(),
        links: Array.from(document.links).slice(0, 5).map(link => ({
            text: link.textContent.trim(),
            href: link.href
        }))
    };
    info;
    """
    
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://example.com",
            js_code=js_code
        )
        
        print(f"âœ… JavaScript åŸ·è¡Œå®Œæˆ")
        if result.js_execution_result:
            print(f"ğŸ“Š åŸ·è¡Œçµæœ: {json.dumps(result.js_execution_result, indent=2, ensure_ascii=False)}")

async def css_selector_test():
    """CSS é¸æ“‡å™¨æ¸¬è©¦"""
    print("\nğŸ¯ é–‹å§‹ CSS é¸æ“‡å™¨æ¸¬è©¦...")
    
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://quotes.toscrape.com",
            css_selector="div.quote"  # é¸æ“‡å¼•ç”¨å€å¡Š
        )
        
        print(f"âœ… CSS é¸æ“‡å™¨æ“·å–å®Œæˆ")
        print(f"ğŸ“ æ“·å–åˆ°çš„å…§å®¹é•·åº¦: {len(result.markdown)} å­—å…ƒ")
        if result.markdown:
            preview = result.markdown[:300] + "..." if len(result.markdown) > 300 else result.markdown
            print(f"ğŸ“– å…§å®¹é è¦½:\n{preview}")

async def screenshot_test():
    """è¢å¹•æˆªåœ–æ¸¬è©¦"""
    print("\nğŸ“¸ é–‹å§‹è¢å¹•æˆªåœ–æ¸¬è©¦...")
    
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://example.com",
            screenshot=True
        )
        
        print(f"âœ… è¢å¹•æˆªåœ–å®Œæˆ")
        if result.screenshot:
            # å„²å­˜æˆªåœ–
            with open("/Users/dennis.lo/crawl4ai.py/screenshot.png", "wb") as f:
                f.write(result.screenshot)
            print(f"ğŸ’¾ æˆªåœ–å·²å„²å­˜è‡³: screenshot.png")

async def user_agent_test():
    """è‡ªè¨‚ User Agent æ¸¬è©¦"""
    print("\nğŸ¤– é–‹å§‹è‡ªè¨‚ User Agent æ¸¬è©¦...")
    
    custom_config = CrawlerRunConfig(
        user_agent="Crawl4AI-Test-Bot/1.0"
    )
    
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://httpbin.org/user-agent",
            config=custom_config
        )
        
        print(f"âœ… User Agent æ¸¬è©¦å®Œæˆ")
        print(f"ğŸ“„ å›æ‡‰å…§å®¹: {result.markdown}")

async def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("ğŸš€ Crawl4AI é€²éšåŠŸèƒ½æ¸¬è©¦ç¨‹å¼")
    print("=" * 60)
    
    try:
        await structured_extraction_test()
        await javascript_execution_test()
        await css_selector_test()
        await screenshot_test()
        await user_agent_test()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰é€²éšæ¸¬è©¦å®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
